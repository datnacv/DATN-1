document.addEventListener("DOMContentLoaded", async () => {
    const video = document.getElementById("video");
    const resultDiv = document.getElementById("result");
    const username = "admin"; // üëà B·∫°n c√≥ th·ªÉ truy·ªÅn ƒë·ªông t·ª´ backend xu·ªëng thay v√¨ hardcode

    console.log("üöÄ B·∫Øt ƒë·∫ßu x√°c minh khu√¥n m·∫∑t cho:", username);

    try {
        resultDiv.textContent = "‚è≥ ƒêang t·∫£i models...";
        await Promise.all([
            faceapi.nets.tinyFaceDetector.loadFromUri("/models"),
            faceapi.nets.faceLandmark68Net.loadFromUri("/models"),
            faceapi.nets.faceRecognitionNet.loadFromUri("/models"),
        ]);
        console.log("‚úÖ ƒê√£ load models th√†nh c√¥ng");

        resultDiv.textContent = "‚è≥ ƒêang m·ªü camera...";
        const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
        video.srcObject = stream;
        console.log("üì∑ Camera ƒë√£ ho·∫°t ƒë·ªông");

    } catch (e) {
        console.error("‚ùå L·ªói khi kh·ªüi t·∫°o camera/models:", e);
        resultDiv.textContent = "L·ªói: " + e.message;
        return;
    }

    video.addEventListener("play", async () => {
        const canvas = document.getElementById("overlay");
        const displaySize = { width: 600, height: 450 };
        faceapi.matchDimensions(canvas, displaySize);

        try {
            resultDiv.textContent = "‚è≥ ƒêang l·∫•y d·ªØ li·ªáu khu√¥n m·∫∑t t·ª´ server...";
            const response = await fetch(`/api/get-descriptor?username=${encodeURIComponent(username)}`);
            const data = await response.json();

            if (!response.ok || !data.descriptors || !Array.isArray(data.descriptors) || data.descriptors.length === 0) {
                throw new Error(data.message || "Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu khu√¥n m·∫∑t");
            }

            const labeledDescriptor = new faceapi.LabeledFaceDescriptors(
                username,
                data.descriptors.map(d => new Float32Array(d))
            );
            const faceMatcher = new faceapi.FaceMatcher([labeledDescriptor], 0.6);

            resultDiv.textContent = "üëÅÔ∏è ƒêang x√°c minh khu√¥n m·∫∑t...";

            let consecutiveMatches = 0;
            const requiredMatches = 3;
            let attempts = 0;
            const maxAttempts = 5;
            let stop = false;

            const detectLoop = async () => {
                if (stop) return;

                const detections = await faceapi
                    .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                    .withFaceLandmarks()
                    .withFaceDescriptors();

                const resized = faceapi.resizeResults(detections, displaySize);
                const ctx = canvas.getContext("2d");
                ctx.clearRect(0, 0, canvas.width, canvas.height);

                if (detections.length === 0) {
                    resultDiv.textContent = "üò∂ Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t. Vui l√≤ng ƒë·ªëi di·ªán camera.";
                    consecutiveMatches = 0;
                    requestAnimationFrame(detectLoop);
                    return;
                }

                const results = resized.map(d => faceMatcher.findBestMatch(d.descriptor));
                let matched = false;

                results.forEach((result, i) => {
                    const box = resized[i].detection.box;
                    const match = result.label === username && result.distance < 0.6;

                    const drawBox = new faceapi.draw.DrawBox(box, {
                        label: match ? `‚úÖ ${result.label} (${result.distance.toFixed(2)})` : `‚ùå ${result.label}`,
                        boxColor: match ? "#00ff00" : "#ff0000"
                    });
                    drawBox.draw(canvas);

                    if (match) {
                        matched = true;
                        consecutiveMatches++;
                        resultDiv.textContent = `‚úÖ ƒê√£ kh·ªõp (${consecutiveMatches}/${requiredMatches})`;

                        if (consecutiveMatches >= requiredMatches) {
                            stop = true;
                            resultDiv.textContent = "üéâ X√°c minh th√†nh c√¥ng!";

                            // G·ª≠i x√°c minh l√™n server
                            fetch("/acvstore/verify-success", { method: "POST" })
                                .then(res => res.json())
                                .then(res => {
                                    if (res.success) {
                                        resultDiv.textContent = "‚úÖ ƒê√£ x√°c minh. Chuy·ªÉn h∆∞·ªõng...";
                                        setTimeout(() => window.location.href = "/acvstore/thong-ke", 1000);
                                    } else {
                                        resultDiv.textContent = "‚ùå X√°c minh th·∫•t b·∫°i!";
                                    }
                                })
                                .catch(err => {
                                    console.error("L·ªói g·ª≠i x√°c minh:", err);
                                    resultDiv.textContent = "‚ùå L·ªói x√°c minh session.";
                                });
                        }
                    }
                });

                if (!matched) {
                    consecutiveMatches = 0;
                    attempts++;
                    resultDiv.textContent = `‚ö†Ô∏è Kh√¥ng kh·ªõp. Th·ª≠ l·∫°i... (${attempts}/${maxAttempts})`;

                    if (attempts >= maxAttempts) {
                        stop = true;
                        resultDiv.textContent = "‚ùå X√°c minh th·∫•t b·∫°i. Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c li√™n h·ªá qu·∫£n tr·ªã vi√™n.";
                    }
                }

                if (!stop) requestAnimationFrame(detectLoop);
            };

            detectLoop();

        } catch (err) {
            console.error("‚ùå L·ªói khi t·∫£i descriptor:", err);
            resultDiv.textContent = "‚ùå " + (err.message || "L·ªói kh√¥ng x√°c ƒë·ªãnh");
        }
    });
});
